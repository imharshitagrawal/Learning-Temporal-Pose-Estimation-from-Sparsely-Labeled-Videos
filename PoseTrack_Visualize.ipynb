{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "PoseTrack-Visualize.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMN6E1ni5HXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os.path as path\n",
        "import os\n",
        "import json\n",
        "from random import randint\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "from skimage.draw import polygon\n",
        "import skimage.io as sio\n",
        "from pycocotools.coco import COCO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdPOEpm5HXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adjust these two variables to:\n",
        "# the root folder of the posetrack data (must contain the 'images' subfolder)\n",
        "posetrack_home_fp = path.expanduser('/content/drive/My Drive/Posetrack 2018')\n",
        "\n",
        "# the annotations folder (must contain 'train', 'val' and 'test' subfolders)\n",
        "posetrack_annotations_fp = os.path.join(posetrack_home_fp, 'annotations')\n",
        "\n",
        "assert(os.path.exists(posetrack_home_fp))\n",
        "assert(os.path.exists(posetrack_annotations_fp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A_9MpCY5HXm",
        "colab_type": "text"
      },
      "source": [
        "Read in an annotation file from PoseTrack:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEUDBVLT5HXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read a PoseTrack sequence.\n",
        "coco = COCO(path.join(posetrack_annotations_fp, 'train/001278_mpii_train.json'))\n",
        "#coco = COCO(path.join(posetrack_annotations_fp, 'test/023732_mpii_train.json'))\n",
        "\n",
        "# or load the full database.\n",
        "# coco = COCO(path.join(posetrack_annotations_fp, 'posetrack.json'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAgbBXoA5HXs",
        "colab_type": "text"
      },
      "source": [
        "Let's filter out images that have no annotations and retrieve a specific sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THT5ofaS5HXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_ids = coco.getImgIds()\n",
        "imgs = coco.loadImgs(img_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3fZPNWX5HXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute this line to see all available sequence IDs.\n",
        "np.unique([img['vid_id'] for img in imgs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kkvSu3ct5HX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posetrack_images = []\n",
        "for img in imgs:\n",
        "    if not img['is_labeled']:  # or img['vid_id'] != '000015':  # Uncomment to filter for a sequence.\n",
        "        pass\n",
        "    else:\n",
        "        posetrack_images.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXezAJ1f5HX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(posetrack_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7FeUCwB5HX8",
        "colab_type": "text"
      },
      "source": [
        "We need a slighly refined `showAnns` function to respect the track_ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Sr0-by5HX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showAnns(anns, coco):\n",
        "    \"\"\"\n",
        "    Display the specified annotations.\n",
        "    :param anns (array of object): annotations to display\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    from matplotlib.collections import PatchCollection\n",
        "    if len(anns) == 0:\n",
        "        return 0\n",
        "    if 'segmentation' in anns[0] or 'keypoints' in anns[0]:\n",
        "        datasetType = 'instances'\n",
        "    elif 'caption' in anns[0]:\n",
        "        datasetType = 'captions'\n",
        "    else:\n",
        "        raise Exception('datasetType not supported')\n",
        "    if datasetType == 'instances':\n",
        "        ax = plt.gca()\n",
        "        ax.set_autoscale_on(False)\n",
        "        polygons = []\n",
        "        color = []\n",
        "        np.random.seed(1)\n",
        "        color_coeffs = np.random.random((31, 3))\n",
        "        for ann_idx, ann in enumerate(anns):\n",
        "            c_assoc = ann['track_id'] * 97 % 31\n",
        "            c = (color_coeffs[c_assoc:c_assoc+1, :]*0.6+0.4).tolist()[0]\n",
        "            if 'keypoints' in ann and type(ann['keypoints']) == list:\n",
        "                # turn skeleton into zero-based index\n",
        "                sks = np.array(coco.loadCats(ann['category_id'])[0]['skeleton'])-1\n",
        "                kp = np.array(ann['keypoints'])\n",
        "                x = kp[0::3]\n",
        "                y = kp[1::3]\n",
        "                v = kp[2::3]\n",
        "                for sk in sks:\n",
        "                    if np.all(v[sk]>0):\n",
        "                        plt.plot(x[sk],y[sk], linewidth=3, color=c)\n",
        "                plt.plot(x[v>0], y[v>0],'o',markersize=8, markerfacecolor=c, markeredgecolor='k',markeredgewidth=2)\n",
        "                plt.plot(x[v>1], y[v>1],'o',markersize=8, markerfacecolor=c, markeredgecolor=c, markeredgewidth=2)\n",
        "        p = PatchCollection(polygons, facecolor=color, linewidths=0, alpha=0.4)\n",
        "        ax.add_collection(p)\n",
        "        p = PatchCollection(polygons, facecolor='none', edgecolors=color, linewidths=2)\n",
        "        ax.add_collection(p)\n",
        "    elif datasetType == 'captions':\n",
        "        for ann in anns:\n",
        "            print(ann['caption'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTn8SNeR5HYB",
        "colab_type": "text"
      },
      "source": [
        "Now let's visualize the first 20 images of the sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AD9eOBm55HYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=[11, 11])\n",
        "for image_idx, selected_im in enumerate(posetrack_images[:20]):\n",
        "    ann_ids = coco.getAnnIds(imgIds=selected_im['id'])\n",
        "    anns = coco.loadAnns(ann_ids)\n",
        "    # Load image.\n",
        "    img = sio.imread(path.join(posetrack_home_fp, selected_im['file_name']))\n",
        "    # Visualize ignore regions if present.\n",
        "    if 'ignore_regions_x' in selected_im.keys():\n",
        "        for region_x, region_y in zip(selected_im['ignore_regions_x'], selected_im['ignore_regions_y']):\n",
        "            rr, cc = polygon(region_y, region_x, img.shape)\n",
        "            img[rr, cc, 1] = 128 + img[rr, cc, 1]/2\n",
        "    # Display.\n",
        "    plt.clf()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    # Visualize keypoints.\n",
        "    showAnns(anns, coco)\n",
        "    # If you want to save the visualizations somewhere:\n",
        "    # plt.savefig(\"vis_{:04d}.png\".format(image_idx))\n",
        "    # Frame updates.\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())\n",
        "    time.sleep(1. / 10.)\n",
        "    # If you want to just look at the first image, uncomment:\n",
        "    # break\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIwvFIxN5uKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}